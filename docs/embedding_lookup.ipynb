{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding_lookup",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit ('rec37': conda)",
      "metadata": {
        "interpreter": {
          "hash": "2447439658606371a14ea77ab6697e9455e3d6c3cf7d1f1d588069ec318e68b9"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Recommending movies: ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfa-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/addons/tutorials/_template\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/_template.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/addons/blob/master/docs/tutorials/_template.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "      <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/addons/docs/tutorials/_template.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "In this tutorial, we're going to use the rating data to predict the user's rating of other movies. To achieve this goal, we will follow the following steps:\n",
        "\n",
        "1. Get our data and do some preprocessing to get the required format.\n",
        "2. Implement a neural collaborative filtering(NeuralCF) model.\n",
        "3. Train the model.\n",
        "\n",
        "Different from the general recommendation model, the model we implemented replaces `tf.nn.embedding_lookup` with `tfra.dynamic_embedding.embedding_lookup`, which can handle super large sparse features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Imports\n",
        "Let's first get our imports out of the way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEk-ibQkDNtF"
      },
      "source": [
        "!pip install -q --upgrad tensorflow-recommenders-addons\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders_addons as tfra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SixWryS704g"
      },
      "source": [
        "## Preparing the dataset\n",
        "\n",
        "This tutorial uses movies reviews provided by the MovieLens 100K dataset, a classic dataset from the GroupLens research group at the University of Minnesota. In order to facilitate processing, we convert the data type of `movie_id` and `user_id` into `int64`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_id\": tf.strings.to_number(x[\"movie_id\"], tf.int64),\n",
        "    \"user_id\": tf.strings.to_number(x[\"user_id\"], tf.int64),\n",
        "    \"user_rating\": x[\"user_rating\"]\n",
        "})\n",
        "\n",
        "tf.random.set_seed(2021)\n",
        "shuffled = ratings.shuffle(100_000, seed=2021, reshuffle_each_iteration=False)\n",
        "\n",
        "dataset_train = shuffled.take(100_000).batch(256)"
      ]
    },
    {
      "source": [
        "## Implementing a model\n",
        "The NCFModel we implemented is very similar to the conventional one, and the main difference lies in the embedding layer. We specify the variable of embedding layer by `tfra.dynamic_embedding.get_variable`. "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NCFModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(NCFModel, self).__init__()\n",
        "        self.embedding_size = 32\n",
        "        self.d0 = Dense(\n",
        "            256,\n",
        "            activation='relu',\n",
        "            kernel_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1),\n",
        "            bias_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1))\n",
        "        self.d1 = Dense(\n",
        "            64,\n",
        "            activation='relu',\n",
        "            kernel_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1),\n",
        "            bias_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1))\n",
        "        self.d2 = Dense(\n",
        "            1,\n",
        "            kernel_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1),\n",
        "            bias_initializer=tf.keras.initializers.RandomNormal(0.0, 0.1))\n",
        "        self.user_embeddings = tfra.dynamic_embedding.get_variable(\n",
        "            name=\"user_dynamic_embeddings\",\n",
        "            dim=self.embedding_size,\n",
        "            initializer=tf.keras.initializers.RandomNormal(-1, 1))\n",
        "        self.movie_embeddings = tfra.dynamic_embedding.get_variable(\n",
        "            name=\"moive_dynamic_embeddings\",\n",
        "            dim=self.embedding_size,\n",
        "            initializer=tf.keras.initializers.RandomNormal(-1, 1))\n",
        "        self.loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    def call(self, batch):\n",
        "        movie_id = batch[\"movie_id\"]\n",
        "        user_id = batch[\"user_id\"]\n",
        "        rating = batch[\"user_rating\"]\n",
        "\n",
        "        user_id_weights = tfra.dynamic_embedding.embedding_lookup(\n",
        "            params=self.user_embeddings,\n",
        "            ids=user_id,\n",
        "            name=\"user-id-weights\")\n",
        "\n",
        "        movie_id_weights = tfra.dynamic_embedding.embedding_lookup(\n",
        "            params=self.movie_embeddings,\n",
        "            ids=movie_id,\n",
        "            name=\"movie-id-weights\")\n",
        "\n",
        "        out = tf.concat([user_id_weights, movie_id_weights], axis=1)\n",
        "        dnn = self.d0(out)\n",
        "        dnn = self.d1(dnn)\n",
        "        out = self.d2(dnn)\n",
        "        out = tf.reshape(out, shape=[-1])\n",
        "        loss = self.loss(rating, out)\n",
        "        return loss"
      ]
    },
    {
      "source": [
        "Let's instantiate the model, and specify the optimizer."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = NCFModel()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "source": [
        "## Training the model\n",
        "After defining the model, we can train the model and observe the change of loss."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(epoch=1):\n",
        "    for _ in range(epoch):\n",
        "        total_loss = np.array([])\n",
        "        for (_, batch) in enumerate(dataset_train):\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss = model(batch)\n",
        "                total_loss = np.append(total_loss, loss)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        print(np.mean(total_loss))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train(10)"
      ]
    },
    {
      "source": [
        "As the model trains, the loss is falling. Through the entire model definition and training process, we can find that the interface between tfra and TensorFlow maintains a good consistency. We can use tfra to build a recommendation model easily by relying on the experience of using TensorFlow, and can effectively handle super large sparse features."
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}